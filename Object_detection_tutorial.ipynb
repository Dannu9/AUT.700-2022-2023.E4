{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c99b33",
   "metadata": {},
   "source": [
    "#   ROS2 | Exercise 4 - Computer Vision\n",
    "\n",
    "##  Task 3 - Object Detection\n",
    "\n",
    "### Pre-requisites\n",
    "Before you begin this Notebook you have to complete the following tasks explained in the handout\n",
    "- [x] Setting up the gazebo simulation as a ROS package\n",
    "- [x] Setting up Conda environment to run this jupyter notebook\n",
    "\n",
    "### Introduction\n",
    "Object detection and its importance in robotics. Opencv Intro. Some images\n",
    "\n",
    "There are 3 parts in this Notebook which covers the following\n",
    "   - 3.1 : Basic Image processing and Opencv contour detection\n",
    "   - 3.2 : Object detection and Tracking with Video\n",
    "   - 3.3 : Object detection and Tracking with ROS2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e83bf",
   "metadata": {},
   "source": [
    "***\n",
    "### 3.1 Basic Image processing with OpenCV \n",
    "\n",
    "### 3.1.1\n",
    "Familiarize yourself with the basic functionalities available in openCV for basic image reading and visualization with this reference [link](https://docs.opencv.org/4.x/db/deb/tutorial_display_image.html). It has both C++ & Python code. We are following python in this notebook. Execute the following code that reads an image file and displays it in an opencv window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d749662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import sys \n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Variables\n",
    "windowName1 = 'Tracking'\n",
    "windowName2 = 'HSV Frame'\n",
    "\n",
    "windowSizeX = 950\n",
    "windowSizeY = 700\n",
    "\n",
    "# Create default window and resize it\n",
    "# Tracking frame\n",
    "cv2.namedWindow(windowName1,cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(windowName1, windowSizeX,windowSizeY)\n",
    "\n",
    "# HSV frame\n",
    "cv2.namedWindow(windowName2,cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(windowName2, windowSizeX,windowSizeY)\n",
    "\n",
    "# Image reading function. NOTICE! By default, the image is read in BGR,NOT in RGB\n",
    "frame = cv2.imread('image.png')\n",
    "\n",
    "# Image processing\n",
    "# Color Space Conversions\n",
    "hsvFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "# Create window(s) whith the title and image\n",
    "cv2.imshow(windowName1,frame)\n",
    "cv2.imshow(windowName2,hsvFrame)\n",
    "\n",
    "# Wait until user presses any key -> destroy window(s)\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3277af99",
   "metadata": {},
   "source": [
    "# 3.1.2\n",
    "\n",
    "It is important to  pre-process raw input images in computer vision tasks such as object detection and tracking. OpenCV imgproc module contains several functionalities which are often used in image processing.\n",
    "\n",
    "Convertion between color spaces is necessary to generate image masks. Execute and observe the following code where you convert an image from RGB to HSV color space. The code generates a mask of the green color object.\n",
    "\n",
    "**Your task**\n",
    "\n",
    "- [x] Change HSV values in order to generate masks of other objects.\n",
    "\n",
    "![RGB vs. HSV](RGB-left-and-HSV-right-color-spaces.png) \n",
    "\n",
    "Acronyms and short descriptions:\n",
    "- HSL (for hue, saturation, lightness) and\n",
    "- HSV (for hue, saturation, value; also known as  HSB (V=B)\n",
    "- HSB, for hue, saturation, brightness) \n",
    "\n",
    "HSL/HSV are alternative representations of the RGB color \n",
    "\n",
    "*Hue* is a colour or shade. Hue is usually a number between 0 and 360 \n",
    "which represents the color wheel.\n",
    "\n",
    "*Lightness* is the amount of white color introduced to the color [0-1]\n",
    "\n",
    "*Saturation* pertains the amount of white light mixed with a hue [0-1]\n",
    "\n",
    "*Brightness and value* represents the perception of the \n",
    "ammount of light or power of the source. [0-1]\n",
    "\n",
    "**Why converting images from BGR -> HSV ?** \n",
    "\"*The simple answer is that unlike RGB, HSV separates luma, or the image intensity, from chroma or the color information. This is very useful in many applications, and is used as masking. For example, if you want to do histogram equalization of a color image, you probably want to do that only on the intensity component, and leave the color components alone. Otherwise you will get very strange colors. In computer vision you often want to separate color components from intensity for various reasons, such as robustness to lighting changes, or removing shadows.*\"  - StackExchange, user Dima\n",
    "\n",
    "**Nice Video by Ben (Learn Code By Gaming), Where the HSV and thresholing is explained well with graphical material** https://www.youtube.com/watch?v=0tKzqsRtmyY [13 min -->]\n",
    "\n",
    "**References**\n",
    "- [Concept of HSL and HSV Color spaces](https://en.wikipedia.org/wiki/HSL_and_HSV)\n",
    "- [Opencv basic Image processing functionalities](https://docs.opencv.org/4.x/d7/da8/tutorial_table_of_content_imgproc.html)\n",
    "- [OpenCV RGB-HSV color converstions documentation](https://docs.opencv.org/3.4.6/de/d25/imgproc_color_conversions.html#color_convert_rgb_hsv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a9bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower and upper boundaries for HSV thresholds\n",
    "# So this means what is the color range which be filtered for the mask\n",
    "\n",
    "# Green plate + yellow gear (DEFAULT)\n",
    "Lower = (29, 86, 6)       \n",
    "Upper = (64, 255, 255)  \n",
    "\n",
    "# Green plate\n",
    "# Lower = (40, 86, 6)       \n",
    "# Upper = (64, 255, 255)    \n",
    "\n",
    "# Turquoise gear\n",
    "# Lower = (68, 86, 6)       \n",
    "# Upper = (90, 255, 255)  \n",
    "\n",
    "# Red gear\n",
    "# Lower = (0, 86, 6)       \n",
    "# Upper = (25, 255, 255) \n",
    "\n",
    "# ALL\n",
    "# Lower = (0, 30, 0)       \n",
    "# Upper = (255, 255, 255) \n",
    "\n",
    "\n",
    "# Preparation function, witch returns original frame and mask\n",
    "def prep(frame):\n",
    "    # Resize the frame, with image utilization tool\n",
    "    frame = imutils.resize(frame, width=600)\n",
    "    \n",
    "    ## Todo 3.1.3 gaussian blur\n",
    "    kernelSizeGaus = 11\n",
    "    blurred = cv2.GaussianBlur(frame,(kernelSizeGaus,kernelSizeGaus),0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv,Lower,Upper)\n",
    "\n",
    "    ## Todo 3.1.3 Erosion / Dialation\n",
    "    kernelSizeEroDia = 3\n",
    "    eroDiaIterations = 1\n",
    "    kernel = np.ones((kernelSizeEroDia, kernelSizeEroDia), np.uint8)\n",
    "    frame_erosion = cv2.erode(frame, kernel, iterations=eroDiaIterations)\n",
    "    frame_dilation = cv2.dilate(frame, kernel, iterations=eroDiaIterations)\n",
    "    \n",
    "    blurEro = cv2.erode(hsv, kernel, iterations=eroDiaIterations)\n",
    "    blurEroDil = cv2.dilate(blurEro, kernel, iterations=eroDiaIterations)\n",
    "    blurEroDilMask = cv2.inRange(blurEroDil,Lower,Upper)\n",
    "    \n",
    "    return mask, frame, frame_erosion, frame_dilation, blurred, blurEroDil, blurEroDilMask\n",
    "\n",
    "mask, frame, frame_erosion, frame_dilation, blurred, blurEroDil, blurEroDilMask = prep(frame)\n",
    "\n",
    "cv2.imshow(\"Image\",frame)\n",
    "cv2.imshow(\"Blurred\",blurred)\n",
    "cv2.imshow(\"Masked Image\",mask)\n",
    "cv2.imshow(\"Erosion\",frame_erosion)\n",
    "cv2.imshow(\"Dilation\",frame_dilation)\n",
    "cv2.imshow(\"Blurred>Erode>Dilate\",blurEroDil)\n",
    "cv2.imshow(\"Blurred>Erode>Dilate>Mask\",blurEroDilMask)\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d861a45",
   "metadata": {},
   "source": [
    "### 3.1.3\n",
    "\n",
    "The above implementation provides a satisfactory result. However, when dealing with noisy images it is important to perform morphological transformations such as smoothing, erotion and dialation to get better results.\n",
    "\n",
    "**Your task**\n",
    "\n",
    "Read the following documentations and implement the following transformations inside the prep_frame() function above.\n",
    "\n",
    "\n",
    "- [ ] Apply Gaussian blur with a kernel size of 11x11\n",
    "- [ ] Apply erosion\n",
    "- [ ] Apply dialation\n",
    "\n",
    "**References**\n",
    "\n",
    "- [Smoothing Images with OpenCV](https://docs.opencv.org/4.5.2/d4/d13/tutorial_py_filtering.html)\n",
    "- [Perform Erosion and Dialation on the image mask using OpenCV](https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7d793",
   "metadata": {},
   "source": [
    "### 3.1.4\n",
    "\n",
    "Finding contours in an image is useful in object detection and tracking. The code snippet below extracts contours from the image file and draws a circle with its center as the same center of detected contour. Execute the code below and observe the results.\n",
    "\n",
    "**References**\n",
    "- [ Detecting contours with OpenCV](https://docs.opencv.org/4.5.0/d4/d73/tutorial_py_contours_begin.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f3d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find contours and display\n",
    "def find_cnts(mask):\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    return cnts\n",
    "\n",
    "# Find contours / cnts is list\n",
    "cnts = find_cnts(mask)\n",
    "\n",
    "# Search contour with largest area / c in numpy array\n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "# Chose what to draw\n",
    "circle = True\n",
    "rectangle = True\n",
    "rectangleRot = True\n",
    "convexHull = True\n",
    "\n",
    "# Frame reference\n",
    "frame1 = frame.copy()\n",
    "\n",
    "if(circle):\n",
    "    # It is a circle which completely covers the object with minimum area. \n",
    "    ((x, y), radius) = cv2.minEnclosingCircle(c) ## A different contour?\n",
    "\n",
    "    # Find center of contour using moments in opencvq\n",
    "    M = cv2.moments(c)\n",
    "    center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "    # Draw circle\n",
    "    cv2.circle(frame1, (int(x), int(y)), int(radius),(0, 0, 255), 0)\n",
    "    cv2.circle(frame1, center, 5, (0, 0, 255), -1)    \n",
    "    cv2.imshow(\"Circle\", frame1)\n",
    "\n",
    "## ToDo 3.1.5 \n",
    "#  1. Bounding rectangle(s)\n",
    "#  2. Convex Hull\n",
    "\n",
    "if(rectangle):\n",
    "    # Calculate xy position and add w and h to them (other corners)\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    \n",
    "    # Draw the rectangle \n",
    "    cv2.rectangle(frame1,(x,y),(x+w,y+h),(255,255,0),1)\n",
    "    \n",
    "    cv2.imshow(\"Rectangle\", frame1)\n",
    "\n",
    "if(rectangleRot):\n",
    "    # Finds a rotated rectangle of the minimum area enclosing the input 2D point set. \n",
    "    rect = cv2.minAreaRect(c)\n",
    "    \n",
    "    # Finds the four vertices of a rotated rect. Useful to draw the rotated rectangle. \n",
    "    box = cv2.boxPoints(rect)\n",
    "    \n",
    "    # Float -> Integer\n",
    "    box = np.int0(box)\n",
    "    \n",
    "    # Draw rectange args(image,contours,contour index, color BGR, thickness, line type ,...)\n",
    "    cv2.drawContours(frame1,[box],0,(0,255,0),1)\n",
    "    cv2.imshow(\"Rectangle Rotate\", frame1)\n",
    "    \n",
    "if(convexHull):\n",
    "    # Find the convex hull of a point set\n",
    "    conhull = cv2.convexHull(c)\n",
    "    \n",
    "    # Draw points\n",
    "    cv2.drawContours(frame1,[conhull],0,(255,0,0),1)\n",
    "    \n",
    "    # Show the window\n",
    "    cv2.imshow(\"Convex Hull\", frame1)\n",
    "\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce9729",
   "metadata": {},
   "source": [
    "### 3.1.5\n",
    "The above implementation only uses a minimum enclosing circle for labelling the detected image. There are more labelling options such as bounding boxes and convex hull which may come handy in various computer vision tasks.\n",
    "\n",
    "**Your task**\n",
    "\n",
    "- [ ] Implement a bounding rectangle and rotated rectangle on the detected contours by modifying the code in 3.1.4 \n",
    "- [ ] Implement a convex hull on the detected contours by modifying the code in 3.1.4\n",
    "\n",
    "**References**\n",
    "- [Contour features in OpenCV](https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html)\n",
    "- [Creating Bounding boxes and circles for contours](https://docs.opencv.org/4.x/da/d0c/tutorial_bounding_rects_circles.html)\n",
    "-[Convex Hull](https://docs.opencv.org/4.x/d7/d1d/tutorial_hull.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08eb8c4",
   "metadata": {},
   "source": [
    "***\n",
    "### 3.2 Object detection and Tracking with Video\n",
    "\n",
    "### 3.2.1\n",
    "\n",
    "Execute and observe the below code snippet which reads frames from a given video file at a pre-defined frame rate.\n",
    "\n",
    "**Your task**\n",
    "- [ ] Implement pre-processing and find contour of the moving blob on by modifiying the same code below\n",
    "- [ ] Implement a suitable labelling mode (Enclosed Circle / bounding Box or convex hull) and display the resulted tracking on a seperated window\n",
    "\n",
    "**Tip** : Use the same functions from 3.1. Avoid creating duplicate functions and unnecessarily lenghty code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52cea68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from imutils.video import VideoStream\n",
    "import time\n",
    "\n",
    "# Lower and upper boundaries for HSV thresholds\n",
    "videoLower = (95, 86, 6)        \n",
    "videoUpper = (120, 255, 255)  \n",
    "\n",
    "# Capture the video\n",
    "vs = cv2.VideoCapture(\"test_video.avi\")\n",
    "\n",
    "# Script sleep\n",
    "time.sleep(2.0)\n",
    "\n",
    "# Variables\n",
    "frame_rate = 30\n",
    "prev = 0\n",
    "\n",
    "while True :\n",
    "    # Time elapsed\n",
    "    time_elapsed = time.time() - prev\n",
    "\n",
    "    # Per frame\n",
    "    if time_elapsed > 1./frame_rate:\n",
    "        # Read frames\n",
    "        video_frame = vs.read()\n",
    "        \n",
    "        # Take the first frame\n",
    "        video_frame = video_frame[1]\n",
    "        \n",
    "        # Check that there is frame data, otherwise the video has ended\n",
    "        if video_frame is None:\n",
    "            break\n",
    "            \n",
    "        # There is available frame, lets size it little bit\n",
    "        video_frame = imutils.resize(video_frame, width=900)\n",
    "        \n",
    "        # Gaussian blur\n",
    "        kernelSizeGaus = 11\n",
    "        video_blurred = cv2.GaussianBlur(video_frame.copy(),(kernelSizeGaus,kernelSizeGaus),0)\n",
    "        \n",
    "        # Frame BGR -> HSV\n",
    "        video_hsvFrame = cv2.cvtColor(video_blurred, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Mask\n",
    "        video_mask = cv2.inRange(video_hsvFrame,videoLower,videoUpper)\n",
    "        \n",
    "        # Erosion / Dialation -> Noice canselation which is caused from hand\n",
    "        kernelSizeEroDia = 9\n",
    "        eroDiaIterations = 1\n",
    "        kernel = np.ones((kernelSizeEroDia, kernelSizeEroDia), np.uint8)\n",
    "        video_maskEro = cv2.erode(video_mask, kernel, iterations=eroDiaIterations)\n",
    "        video_mask = cv2.dilate(video_maskEro, kernel, iterations=eroDiaIterations)\n",
    "        \n",
    "        # Contour of the object \n",
    "        \n",
    "        # Find contours / cnts is list\n",
    "        video_cnts = find_cnts(video_mask)\n",
    "        \n",
    "        # Take the largest object array / numpy array\n",
    "        video_c = max(video_cnts, key=cv2.contourArea)\n",
    "        \n",
    "        # Find the convex hull of a point set\n",
    "        video_conhull = cv2.convexHull(video_c)\n",
    "          \n",
    "        # Draw points\n",
    "        cv2.drawContours(video_frame,[video_conhull],0,(255,255,0),3)\n",
    "\n",
    "        # Show frame\n",
    "        cv2.imshow(\"Modified video\", video_mask)\n",
    "        cv2.imshow(\"Original video with contour\", video_frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        prev = time.time()\n",
    "            \n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4da8f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  3.3 Object detection and Tracking with ROS2\n",
    "\n",
    "### 3.3.1 \n",
    "\n",
    "In applications concerning robotic perception, so often visual data are obtained via camera sensors interfaced with ros. In this section you are provided with a ros-ignition simulation package which publish camera sensor data. The code snippet below subscribes to the camera sensor data and stream on to an OpenCV window. \n",
    "\n",
    "Assuming you have successfully build the package on your system using the instructions from handout, Open a New shell in you terminal and launch the simulation.\n",
    "\n",
    "```\n",
    "$ source /opt/ros/foxy/setup.bash\n",
    "$ cd ~/ws\n",
    "$ source install/setup.bash\n",
    "$ ros2 launch walking_actor cam_world.launch.py\n",
    "```\n",
    "\n",
    "While the simulation is running in background , run the code snippet below and observe the result\n",
    "\n",
    "- To close the cv2 window , select the window and press 'q'\n",
    "- To stop the execution of code snippet, double press on 'i' in keyboard or interrupt the kernel from menu\n",
    "\n",
    "\n",
    "**Your task**\n",
    "\n",
    "- [ ] Modify the python code to track the walking actor. You can use any feature of the actor to track.\n",
    "- [ ] Display the tracking in a seperate cv2 window\n",
    "\n",
    "\n",
    "**References**\n",
    "- [ROS2 python subscriber/publisher](https://docs.ros.org/en/foxy/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html)\n",
    "- [rclpy API Documentation](https://docs.ros2.org/foxy/api/rclpy/api/execution_and_callbacks.html#module-rclpy.executors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import rclpy\n",
    "import imutils\n",
    "from rclpy.node import Node\n",
    "from cv_bridge import CvBridge\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "\n",
    "# Bridge variable\n",
    "bridge = CvBridge()\n",
    "\n",
    "# Lower and upper boundaries for HSV thresholds\n",
    "rosLower = (10, 60, 40)        \n",
    "rosUpper = (140, 255, 255) \n",
    "\n",
    "\n",
    "class Get_Images(Node):\n",
    "\n",
    "    # Constructor \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Initialize the node\n",
    "        super().__init__('Image_Subscriber')\n",
    "        \n",
    "        # Initialize the subscriber\n",
    "        self.subscription_ = self.create_subscription(Image,'/camera', self.listener_callback,10)\n",
    "        self.subscription_  # prevent unused variable warning\n",
    "        \n",
    "        # Timer function\n",
    "        timer_period = 0.1  # seconds -> new image every 100ms \n",
    "        self.frame = None\n",
    "        self.timer = self.create_timer(timer_period, self.timer_callback)\n",
    "        self.K = True       # Ok variable\n",
    "\n",
    "    # Subscribe callback function\n",
    "    def listener_callback(self, msg):\n",
    "        \n",
    "        # Get the size of the frame and channel\n",
    "        height = msg.height\n",
    "        width = msg.width\n",
    "        channel = msg.step//msg.width\n",
    "        \n",
    "        #frame = np.reshape(msg.data, (height, width, channel))\n",
    "        \n",
    "        # Set data to frame variable\n",
    "        self.frame =  bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n",
    "        \n",
    "        # Log when image was received\n",
    "        self.get_logger().info(\"Image Received\")\n",
    "        return self.frame\n",
    "    \n",
    "    def timer_callback(self):\n",
    "        if self.K == True:\n",
    "\n",
    "            if self.frame is None:\n",
    "                return\n",
    "\n",
    "            mod_frame = self.frame.copy()\n",
    "\n",
    "            # Gaussian blur\n",
    "            rosKernelSizeGaus = 15\n",
    "            ros_blurred = cv2.GaussianBlur(mod_frame,(rosKernelSizeGaus,rosKernelSizeGaus),0)\n",
    "\n",
    "            # Frame BGR -> HSV\n",
    "            ros_hsvFrame = cv2.cvtColor(ros_blurred, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Mask\n",
    "            ros_mask = cv2.inRange(ros_hsvFrame,rosLower,rosUpper)\n",
    "\n",
    "            # Erosion / Dialation -> Soft noice cancelation\n",
    "            rosKernelSizeEroDia = 7\n",
    "            rosEroDiaIterations = 1\n",
    "            rosKernel = np.ones((rosKernelSizeEroDia, rosKernelSizeEroDia), np.uint8)\n",
    "            rosMaskEro = cv2.erode(ros_mask, rosKernel, iterations=rosEroDiaIterations)\n",
    "            ros_mask = cv2.dilate(rosMaskEro, rosKernel, iterations=rosEroDiaIterations)\n",
    "\n",
    "            # Contour of the object \n",
    "\n",
    "            # Find contours / cnts is list\n",
    "            ros_cnts = find_cnts(ros_mask)\n",
    "\n",
    "            # Take the largest object array / numpy array\n",
    "            ros_c = max(ros_cnts, key=cv2.contourArea)\n",
    "\n",
    "            # Calculate xy position and add w and h to them (other corners)\n",
    "            x,y,w,h = cv2.boundingRect(ros_c)\n",
    "\n",
    "            # Draw the rectangle \n",
    "            cv2.rectangle(self.frame,(x,y),(x+w,y+h),(255,255,0),1)\n",
    "\n",
    "            # Show frame\n",
    "            cv2.imshow(\"Tracking\", ros_mask)\n",
    "            cv2.imshow(\"Original with contour\",self.frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(\"q\"):\n",
    "                self.get_logger().info('Closing stream window..')\n",
    "                self.K = False\n",
    "                cv2.destroyAllWindows()\n",
    "   \n",
    "    def stop_stream(self):\n",
    "        self.get_logger().info('Stopping the stream ...')\n",
    "        \n",
    "### Find contours and display\n",
    "def find_cnts(mask):\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    return cnts\n",
    "\n",
    "try:\n",
    "    \n",
    "    rclpy.init(args=None)\n",
    "    image_subscriber = Get_Images()\n",
    "    rclpy.spin(image_subscriber)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # executes on keyboard kernal interrupt with double pressing button \"i\"\n",
    "    image_subscriber.stop_stream()\n",
    "    image_subscriber.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af2ad66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tracker)",
   "language": "python",
   "name": "tracker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
